{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a99c1cb-f7ec-4a9e-9bf1-0fe415ce1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9e831d-a62b-4b3e-823a-c8094d3cfd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model = joblib.load('questions-categorizer-v2-KNeighborsClassifier.model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349e00a3-0e76-450f-94cc-67654bc33f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Question Response  Access Count\n",
      "0                               0\n",
      "1                               0\n",
      "2                               0\n",
      "3                               0\n"
     ]
    }
   ],
   "source": [
    "# Initialize fixed size dataframe to setup cache (LFU)\n",
    "num_rows = 4  # Size of the cache\n",
    "columns = ['Question', 'Response', 'Access Count']\n",
    "# Create a list of dictionaries with default values\n",
    "data = [{'Question': '', 'Response': '', 'Access Count': 0} for _ in range(num_rows)]\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "cache_for_VM = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "print(cache_for_VM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1896e5f5-a8e2-42d7-bb6f-7ca02c733965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does TLB caching improve virtual memory performance?\n",
      "Question        How does TLB caching improve virtual memory pe...\n",
      "Response                                                  Resp 23\n",
      "Access Count                                                    1\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# New values for the row\n",
    "new_values = {'Question': 'How does TLB caching improve virtual memory performance?', 'Response': 'Resp 23', 'Access Count': 1}\n",
    "\n",
    "print(new_values['Question'])\n",
    "\n",
    "# Change the values using .loc[]\n",
    "cache_for_VM.loc[2] = new_values\n",
    "\n",
    "print(cache_for_VM.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e9638d-8c8a-459e-ba9b-8db2f3fbf0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11883842  0.04829867 -0.00254811 ...  0.1264095   0.04654902\n",
      "  -0.01571722]\n",
      " [-0.11883842  0.04829867 -0.00254811 ...  0.1264095   0.04654902\n",
      "  -0.01571722]\n",
      " [ 0.00430944  0.05077931 -0.00995335 ... -0.06675059 -0.03632696\n",
      "  -0.06660837]\n",
      " [-0.11883842  0.04829867 -0.00254811 ...  0.1264095   0.04654902\n",
      "  -0.01571722]]\n"
     ]
    }
   ],
   "source": [
    "# encoded cache files\n",
    "embeddings_cache_for_VM = embedder.encode(cache_for_VM['Question'])\n",
    "print(embeddings_cache_for_VM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee5c28b1-6a5a-4f04-93fb-5389976ddc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_the_response(new_request, category):\n",
    "  encoded_new_request = embedder.encode(new_request)\n",
    "\n",
    "  response = cache_handler(new_request, encoded_new_request, category)\n",
    "  return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d2cfcc1-177c-4e04-bdbe-390f5040db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_handler(request, encoded_request, category):\n",
    "  if category == \"vm\":\n",
    "    cos_sim = util.cos_sim(embeddings_cache_for_VM, encoded_request)\n",
    "    if (max(cos_sim) > 0.75):\n",
    "      print(\"* * * * * * * From Cache * * * * * * * \")\n",
    "      print(cos_sim.argmax().item())\n",
    "      return cache_for_VM.iloc[cos_sim.argmax().item()][1]\n",
    "    else:\n",
    "      return call_API(request)\n",
    "  # add other categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "81931f6d-a001-4bf8-af8b-dbee942dbdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_API(request):\n",
    "  print(\"* * * * * * * Calling API * * * * * * * \")\n",
    "  mock_resp = \"API response for -> \" + request\n",
    "  #Add response and question to the cache\n",
    "  new_value = {'Question': 'How does virtual memory support memory protection and isolation between processes?', 'Response': 'Resp 15', 'Access Count': 0}\n",
    "  cacheVM.add_record(new_value)\n",
    "  return mock_resp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6c946bb-e07c-4bac-b1f8-95f8346f216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"can you please tell me how can we improve performances of cache using TLB?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b640330-c67f-4999-a860-bb3a9478b07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * From Cache * * * * * * * \n",
      "2\n",
      "Resp 23\n"
     ]
    }
   ],
   "source": [
    "category = \"vm\"\n",
    "response_for_test_sentence = give_the_response(test_sentence, category)\n",
    "print(response_for_test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a650b42-30f3-4f0c-9c7f-8630dd3bf794",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheLFU:\n",
    "    def __init__(self, category):\n",
    "        \"\"\"\n",
    "        Create a new cache object.\n",
    "\n",
    "        Args:\n",
    "            category: The category of the cache.  \n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        self.category = category\n",
    "        self.size = 4\n",
    "        # Initialize fixed size dataframe\n",
    "        columns = ['Question', 'Response', 'Access Count']\n",
    "        # Create a list of dictionaries with default values\n",
    "        data = [{'Question': '', 'Response': '', 'Access Count': 0} for _ in range(self.size)]\n",
    "        # Create a DataFrame from the list of dictionaries\n",
    "        self.cache_df = pd.DataFrame(data, columns=columns)\n",
    "        #encode questions\n",
    "        self.embeddings_cache = embedder.encode(self.cache_df['Question'])\n",
    "        print(self.category, \"cache initialized\")\n",
    "        print(len(self.embeddings_cache))   \n",
    "        \n",
    "    def add_record(self, new_values):\n",
    "        \"\"\"\n",
    "        Add a new record to the cache.\n",
    "\n",
    "        Args:\n",
    "            new_values (dict): The new record values. Ex - {'Question': 'How does TLB caching improve virtual memory performance?', 'Response': 'Resp 23', 'Access Count': 0}\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check if the cache is full.\n",
    "        if len(self.cache_df) == self.size:\n",
    "            # Get the least accessed question in the cache.\n",
    "            least_accessed_question = self.cache_df[self.cache_df['Access Count'] == self.cache_df['Access Count'].min()].iloc[0]\n",
    "            print(\"Least accessed question:\", least_accessed_question)\n",
    "            removing_record_index = least_accessed_question.name\n",
    "            print(\"Removing record with index\", removing_record_index)\n",
    "            \n",
    "            self.cache_df.loc[removing_record_index] = new_values\n",
    "            \n",
    "            # Encode the new question\n",
    "            encoded_question = embedder.encode(new_values['Question'])\n",
    "            \n",
    "            # Update the embeddings cache.\n",
    "            self.embeddings_cache[removing_record_index] = encoded_question\n",
    "    \n",
    "    def update_count(self, index):\n",
    "        \"\"\"\n",
    "        Update the access count of a record.\n",
    "\n",
    "        Args:\n",
    "            index (int): The index of the record to be updated.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        self.cache_df.loc[index, 'Access Count'] += 1\n",
    "\n",
    "    def get_response(self, index):\n",
    "        \"\"\"\n",
    "        Get the response for a record.\n",
    "\n",
    "        Args:\n",
    "            index (int): The index of the record to be retrieved.\n",
    "\n",
    "        Returns:\n",
    "            str: The response for the record.\n",
    "        \"\"\"\n",
    "        return self.cache_df.loc[index, 'Response']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "28ebd999-c7e6-4424-876a-9b220e48f718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VM cache initialized\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "cacheVM = CacheLFU(\"VM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "33f8d74b-6bc1-4c04-8dcc-1563abb43631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_handler_v2(request, encoded_request, category):\n",
    "  if category == \"vm\":\n",
    "    cos_sim = util.cos_sim(cacheVM.embeddings_cache, encoded_request)\n",
    "    if (max(cos_sim) > 0.75):\n",
    "      print(\"* * * * * * * From Cache * * * * * * * \")\n",
    "      print(cos_sim.argmax().item())\n",
    "      # Update the access count\n",
    "      cacheVM.update_count(cos_sim.argmax().item())\n",
    "      return cacheVM.get_response(cos_sim.argmax().item())\n",
    "    else:\n",
    "      return call_API(request)\n",
    "  # add other categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5ed4f37-fd86-4fcb-ad82-87161ee749d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_the_response_v2(new_request, category):\n",
    "  encoded_new_request = embedder.encode(new_request)\n",
    "\n",
    "  response = cache_handler_v2(new_request, encoded_new_request, category)\n",
    "  return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c0670939-021b-4a49-9bb3-e26f0192fecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * From Cache * * * * * * * \n",
      "2\n",
      "Resp 15\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"can you please tell me how virtual memory support memory protection and isolation between processes?\"\n",
    "category = \"vm\"\n",
    "response_for_test_sentence = give_the_response_v2(test_sentence, category)\n",
    "print(response_for_test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5aa70ac5-50fb-4815-86c5-f376fcd141fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Question Response  Access Count\n",
      "0       How does swapping affect system performance?  Resp 17             4\n",
      "1  How does TLB caching improve virtual memory pe...  Resp 23            15\n",
      "2  How does virtual memory support memory protect...  Resp 15             2\n",
      "3  How does virtual memory help in managing memor...   Resp 9             4\n"
     ]
    }
   ],
   "source": [
    "print(cacheVM.cache_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dbbffae0-3137-4ec8-8bdc-1a7447eae4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00736909  0.00921233 -0.01392672 ... -0.05852419 -0.09660058\n",
      "  -0.09026206]\n",
      " [ 0.00430942  0.05077929 -0.00995335 ... -0.06675062 -0.03632697\n",
      "  -0.06660838]\n",
      " [-0.11883846  0.04829861 -0.00254809 ...  0.12640952  0.04654904\n",
      "  -0.01571725]\n",
      " [-0.11883838  0.04829865 -0.00254807 ...  0.12640947  0.04654909\n",
      "  -0.01571732]]\n"
     ]
    }
   ],
   "source": [
    "print(cacheVM.embeddings_cache)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
